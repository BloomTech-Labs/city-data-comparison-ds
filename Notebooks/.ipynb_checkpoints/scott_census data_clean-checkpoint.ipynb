{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the data\n",
    "\n",
    "### In this notebook we clean the data in the all_census_data.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('all_census_data.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {'Alabama': 'AL',\n",
    "         'Alaska': 'AK',\n",
    "         'Arizona': 'AZ',\n",
    "         'Arkansas': 'AR',\n",
    "         'California': 'CA',\n",
    "         'Colorado': 'CO',\n",
    "         'Connecticut': 'CT',\n",
    "         'Delaware': 'DE',\n",
    "         'Florida': 'FL',\n",
    "         'Georgia': 'GA',\n",
    "         'Hawaii': 'HI',\n",
    "         'Idaho': 'ID',\n",
    "         'Illinois': 'IL',\n",
    "         'Indiana': 'IN',\n",
    "         'Iowa': 'IA',\n",
    "         'Kansas': 'KS',\n",
    "         'Kentucky': 'KY',\n",
    "         'Louisiana': 'LA',\n",
    "         'Maine': 'ME',\n",
    "         'Maryland': 'MD',\n",
    "         'Massachusetts': 'MA',\n",
    "         'Michigan': 'MI',\n",
    "         'Minnesota': 'MN',\n",
    "         'Mississippi': 'MS',\n",
    "         'Missouri': 'MO',\n",
    "         'Montana': 'MT',\n",
    "         'Nebraska': 'NE',\n",
    "         'Nevada': 'NV',\n",
    "         'New Hampshire': 'NH',\n",
    "         'New Jersey': 'NJ',\n",
    "         'New Mexico': 'NM',\n",
    "         'New York': 'NY',\n",
    "         'North Carolina': 'NC',\n",
    "         'North Dakota': 'ND',\n",
    "         'Ohio': 'OH',\n",
    "         'Oklahoma': 'OK',\n",
    "         'Oregon': 'OR',\n",
    "         'Pennsylvania': 'PA',\n",
    "         'Rhode Island': 'RI',\n",
    "         'South Carolina': 'SC',\n",
    "         'South Dakota': 'SD',\n",
    "         'Tennessee': 'TN',\n",
    "         'Texas': 'TX',\n",
    "         'Utah': 'UT',\n",
    "         'Vermont': 'VT',\n",
    "         'Virginia': 'VA',\n",
    "         'Washington': 'WA',\n",
    "         'West Virginia': 'WV',\n",
    "         'Wisconsin': 'WI',\n",
    "         'Wyoming': 'WY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "\n",
    "def clean_nan(x):\n",
    "    \"\"\"\n",
    "    Cleans all columns in dataset that have missing data in the rows\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(x) == str:\n",
    "        if '-' in x:\n",
    "            return 0\n",
    "        elif '(X)' in x:\n",
    "            return np.nan\n",
    "        #otherwise...\n",
    "    return x\n",
    "\n",
    "\n",
    "def clean_names(x):\n",
    "    \"\"\"\n",
    "    clears city names of city town village borough\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'city' in x:\n",
    "        x = x.replace('city', '')\n",
    "    elif 'town' in x:\n",
    "        x = x.replace('town', '')\n",
    "    elif 'village' in x:\n",
    "        x = x.replace('village', '') \n",
    "    elif 'borough' in x:\n",
    "        x = x.replace('borough', '')\n",
    "        \n",
    "    x = x.replace(' ,',',') # fixes 'cityname , state' to 'cityname, state'\n",
    "    return x\n",
    "\n",
    "def state_abrev(name):\n",
    "    \"\"\"\n",
    "    Replaces the state in the name column to abbreviation \n",
    "    \"\"\"\n",
    "    \n",
    "    for x in states:\n",
    "        if x in name:\n",
    "            name = name.replace(x,states[x])\n",
    "    return name\n",
    "\n",
    "def wrangle(X):\n",
    "    \"\"\"\n",
    "    This function will clean and restructure the dataset\n",
    "    \"\"\"\n",
    "    X = X.drop(index = 0) # drop first row\n",
    "    X['NAME'] = X['NAME'].apply(state_abrev)\n",
    "    X['NAME'] = X['NAME'].apply(clean_names)\n",
    "    for column_name in df.columns:\n",
    "        X[column_name] = X[column_name].apply(clean_nan)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GEO_ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DP02_0001E</th>\n",
       "      <th>DP02_0001M</th>\n",
       "      <th>DP02_0001PE</th>\n",
       "      <th>DP02_0001PM</th>\n",
       "      <th>DP02_0002E</th>\n",
       "      <th>DP02_0002M</th>\n",
       "      <th>DP02_0002PE</th>\n",
       "      <th>...</th>\n",
       "      <th>DP05_0087PE</th>\n",
       "      <th>DP05_0087PM</th>\n",
       "      <th>DP05_0088E</th>\n",
       "      <th>DP05_0088M</th>\n",
       "      <th>DP05_0088PE</th>\n",
       "      <th>DP05_0088PM</th>\n",
       "      <th>DP05_0089E</th>\n",
       "      <th>DP05_0089M</th>\n",
       "      <th>DP05_0089PE</th>\n",
       "      <th>DP05_0089PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600000US0167056</td>\n",
       "      <td>Russellville, AL</td>\n",
       "      <td>3208</td>\n",
       "      <td>282</td>\n",
       "      <td>3208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2195</td>\n",
       "      <td>213</td>\n",
       "      <td>68.4</td>\n",
       "      <td>...</td>\n",
       "      <td>5370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2750</td>\n",
       "      <td>397</td>\n",
       "      <td>51.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2620</td>\n",
       "      <td>260</td>\n",
       "      <td>48.8</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1600000US0178984</td>\n",
       "      <td>Vina, AL</td>\n",
       "      <td>146</td>\n",
       "      <td>37</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>30</td>\n",
       "      <td>69.2</td>\n",
       "      <td>...</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>43</td>\n",
       "      <td>50.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>131</td>\n",
       "      <td>44</td>\n",
       "      <td>49.1</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1600000US0162688</td>\n",
       "      <td>Providence, AL</td>\n",
       "      <td>101</td>\n",
       "      <td>29</td>\n",
       "      <td>101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>61.4</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108</td>\n",
       "      <td>43</td>\n",
       "      <td>52.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>96</td>\n",
       "      <td>30</td>\n",
       "      <td>47.1</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1600000US0131096</td>\n",
       "      <td>Grant, AL</td>\n",
       "      <td>367</td>\n",
       "      <td>58</td>\n",
       "      <td>367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273</td>\n",
       "      <td>50</td>\n",
       "      <td>74.4</td>\n",
       "      <td>...</td>\n",
       "      <td>798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>356</td>\n",
       "      <td>81</td>\n",
       "      <td>44.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>442</td>\n",
       "      <td>106</td>\n",
       "      <td>55.4</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1600000US0119816</td>\n",
       "      <td>Daviston, AL</td>\n",
       "      <td>93</td>\n",
       "      <td>29</td>\n",
       "      <td>93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>22</td>\n",
       "      <td>82.8</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113</td>\n",
       "      <td>38</td>\n",
       "      <td>55.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>90</td>\n",
       "      <td>31</td>\n",
       "      <td>44.3</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2093 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            GEO_ID              NAME DP02_0001E DP02_0001M  \\\n",
       "1           1  1600000US0167056  Russellville, AL       3208        282   \n",
       "2           2  1600000US0178984          Vina, AL        146         37   \n",
       "3           3  1600000US0162688    Providence, AL        101         29   \n",
       "4           4  1600000US0131096         Grant, AL        367         58   \n",
       "5           5  1600000US0119816      Daviston, AL         93         29   \n",
       "\n",
       "  DP02_0001PE  DP02_0001PM DP02_0002E DP02_0002M DP02_0002PE  ... DP05_0087PE  \\\n",
       "1        3208          NaN       2195        213        68.4  ...        5370   \n",
       "2         146          NaN        101         30        69.2  ...         267   \n",
       "3         101          NaN         62         25        61.4  ...         204   \n",
       "4         367          NaN        273         50        74.4  ...         798   \n",
       "5          93          NaN         77         22        82.8  ...         203   \n",
       "\n",
       "  DP05_0087PM DP05_0088E DP05_0088M DP05_0088PE DP05_0088PM DP05_0089E  \\\n",
       "1         NaN       2750        397        51.2         4.3       2620   \n",
       "2         NaN        136         43        50.9         6.8        131   \n",
       "3         NaN        108         43        52.9         8.9         96   \n",
       "4         NaN        356         81        44.6         4.7        442   \n",
       "5         NaN        113         38        55.7         9.4         90   \n",
       "\n",
       "  DP05_0089M DP05_0089PE DP05_0089PM  \n",
       "1        260        48.8         4.3  \n",
       "2         44        49.1         6.8  \n",
       "3         30        47.1         8.9  \n",
       "4        106        55.4         4.7  \n",
       "5         31        44.3         9.4  \n",
       "\n",
       "[5 rows x 2093 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply wrangle function to datasetW\n",
    "clean_df = wrangle(df)\n",
    "\n",
    "clead_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of cities not found: 27\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Now we need to check to see if the top populated cities are within the dataset\n",
    "df_pop_top = pd.read_csv('top_1000_cities_US.csv')\n",
    "\n",
    "# Get all city names into a list without state\n",
    "city_names = []\n",
    "for name in clean_df['NAME']:\n",
    "    temp = str(name).split(',') # Not sure why I am needing to cast to str type: for some reason name column is int type\n",
    "    city_names.append(temp[0])\n",
    "    \n",
    "# Now we are able to check if the top 1000 cities are within our data\n",
    "city_not_in_data = []\n",
    "for name in df_pop_top['City Name']:\n",
    "    if name not in city_names:\n",
    "        city_not_in_data.append(name)\n",
    "        \n",
    "print('The amount of cities not found:', len(city_not_in_data))\n",
    "print('Phoenix' in city_names)\n",
    "print('Phoenix city' in city_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
